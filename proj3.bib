%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for sophie huebler at 2020-11-28 11:06:56 -0600 


%% Saved with string encoding Unicode (UTF-8) 



@misc{QQ,
	date-added = {2020-11-28 11:06:44 -0600},
	date-modified = {2020-11-28 11:06:53 -0600},
	month = {Nov},
	title = {{Understanding Q-Q Plots {$\vert$} University of Virginia Library Research Data Services + Sciences}},
	url = {https://data.library.virginia.edu/understanding-q-q-plots},
	year = {2020},
	Bdsk-Url-1 = {https://data.library.virginia.edu/understanding-q-q-plots}}

@misc{autocorr,
	date-added = {2020-11-28 10:29:16 -0600},
	date-modified = {2020-11-28 10:29:23 -0600},
	journal = {Statistics Solutions},
	month = {Jun},
	title = {{Assumptions of Linear Regression - Statistics Solutions}},
	url = {https://www.statisticssolutions.com/assumptions-of-linear-regression},
	year = {2020},
	Bdsk-Url-1 = {https://www.statisticssolutions.com/assumptions-of-linear-regression}}

@inbook{cook,
	address = {Berlin, Heidelberg},
	author = {Cook, R. Dennis},
	booktitle = {International Encyclopedia of Statistical Science},
	da = {2011//},
	date-added = {2020-11-13 18:12:32 -0600},
	date-modified = {2020-11-13 18:12:39 -0600},
	doi = {10.1007/978-3-642-04898-2{\_}189},
	editor = {Lovric, Miodrag},
	id = {Cook2011},
	isbn = {978-3-642-04898-2},
	pages = {301--302},
	publisher = {Springer Berlin Heidelberg},
	title = {Cook's Distance},
	ty = {CHAP},
	url = {https://doi.org/10.1007/978-3-642-04898-2_189},
	year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-642-04898-2_189},
	Bdsk-Url-2 = {https://doi.org/10.1007/978-3-642-04898-2%7B%5C_%7D189}}

@article{boot,
	abstract = {The linear model often serves as a starting point for applying statistics in psychology. Often, formal training beyond the linear model is limited, creating a potential pedagogical gap because of the pervasiveness of data non-normality. We reviewed 61 recently published undergraduate and graduate textbooks on introductory statistics and the linear model, focusing on their treatment of non-normality. This review identified at least eight distinct methods suggested to address non-normality, which we organize into a new taxonomy according to whether the approach: (a) remains within the linear model, (b) changes the data, and (c) treats normality as informative or as a nuisance. Because textbook coverage of these methods was often cursory, and methodological papers introducing these approaches are usually inaccessible to non-statisticians, this review is designed to be the happy medium. We provide a relatively non-technical review of advanced methods which can address non-normality (and heteroscedasticity), thereby serving a starting point to promote best practice in the application of the linear model. We also present three empirical examples to highlight distinctions between these methods' motivations and results. The paper also reviews the current state of methodological research in addressing non-normality within the linear modeling framework. It is anticipated that our taxonomy will provide a useful overview and starting place for researchers interested in extending their knowledge in approaches developed to address non-normality from the perspective of the linear model.},
	author = {Pek, Jolynn and Wong, Octavia and Wong, Augustine C. M.},
	date-added = {2020-11-13 18:08:03 -0600},
	date-modified = {2020-11-13 18:08:07 -0600},
	doi = {10.3389/fpsyg.2018.02104},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	pages = {2104},
	title = {How to Address Non-normality: A Taxonomy of Approaches, Reviewed, and Illustrated},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.02104},
	volume = {9},
	year = {2018},
	Bdsk-Url-1 = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.02104},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2018.02104}}

@inbook{bc,
	address = {Berlin, Heidelberg},
	author = {Daimon, Takashi},
	booktitle = {International Encyclopedia of Statistical Science},
	date-added = {2020-11-13 14:08:47 -0600},
	date-modified = {2020-11-13 14:08:54 -0600},
	doi = {10.1007/978-3-642-04898-2_152},
	editor = {Lovric, Miodrag},
	isbn = {978-3-642-04898-2},
	pages = {176--178},
	publisher = {Springer Berlin Heidelberg},
	title = {Box--Cox Transformation},
	url = {https://doi.org/10.1007/978-3-642-04898-2_152},
	year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-642-04898-2_152}}

@article{nonpar,
	author = {Liu, Wei and Yang, Yuhong},
	date-added = {2020-11-13 12:48:12 -0600},
	date-modified = {2020-11-13 12:48:19 -0600},
	doi = {10.1214/11-AOS899},
	fjournal = {Annals of Statistics},
	journal = {Ann. Statist.},
	month = {08},
	number = {4},
	pages = {2074--2102},
	publisher = {The Institute of Mathematical Statistics},
	title = {Parametric or nonparametric? A parametricness index for model selection},
	url = {https://doi.org/10.1214/11-AOS899},
	volume = {39},
	year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1214/11-AOS899}}

@article{bp,
	abstract = {No abstract is available for this item.},
	author = {Breusch, T S and Pagan, A R},
	date-added = {2020-11-13 01:50:31 -0600},
	date-modified = {2020-11-13 01:50:40 -0600},
	journal = {Econometrica},
	month = {September},
	number = {5},
	pages = {1287-1294},
	title = {{A Simple Test for Heteroscedasticity and Random Coefficient Variation}},
	url = {https://ideas.repec.org/a/ecm/emetrp/v47y1979i5p1287-94.html},
	volume = {47},
	year = 1979,
	Bdsk-Url-1 = {https://ideas.repec.org/a/ecm/emetrp/v47y1979i5p1287-94.html},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxApLi4vLi4vLi4vLi4vRG93bmxvYWRzL0JpYkVudHJ5MjAyMEp1bi5iaWJPEQGCAAAAAAGCAAIAABdBUFBMRSBTU0QgU00wNTEyRyBNZWRpYQAAAAAAAAAAQkQAAf////8TQmliRW50cnkyMDIwSnVuLmJpYgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////wAAAAAAAAAAAAAAAAAEAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgAzLzpVc2Vyczpzb3BoaWVodWVibGVyOkRvd25sb2FkczpCaWJFbnRyeTIwMjBKdW4uYmliAAAOACgAEwBCAGkAYgBFAG4AdAByAHkAMgAwADIAMABKAHUAbgAuAGIAaQBiAA8AMAAXAEEAUABQAEwARQAgAFMAUwBEACAAUwBNADAANQAxADIARwAgAE0AZQBkAGkAYQASADFVc2Vycy9zb3BoaWVodWVibGVyL0Rvd25sb2Fkcy9CaWJFbnRyeTIwMjBKdW4uYmliAAATAAEvAAAVAAIAFP//AAAACAANABoAJABQAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAdY=}}

@article{ci,
	abstract = {Biomedical research is seldom done with entire populations but rather with samples drawn from a population. Although we work with samples, our goal is to describe and draw inferences regarding the underlying population. It is possible to use a sample statistic and estimates of error in the sample to get a fair idea of the population parameter, not as a single value, but as a range of values. This range is the confidence interval (CI) which is estimated on the basis of a desired confidence level. Calculation of the CI of a sample statistic takes the general form: CI = Point estimate $\pm$Margin of error, where the margin of error is given by the product of a critical value (z) derived from the standard normal curve and the standard error of point estimate. Calculation of the standard error varies depending on whether the sample statistic of interest is a mean, proportion, odds ratio (OR), and so on. The factors affecting the width of the CI include the desired confidence level, the sample size and the variability in the sample. Although the 95{\%} CI is most often used in biomedical research, a CI can be calculated for any level of confidence. A 99{\%} CI will be wider than 95{\%} CI for the same sample. Conflict between clinical importance and statistical significance is an important issue in biomedical research. Clinical importance is best inferred by looking at the effect size, that is how much is the actual change or difference. However, statistical significance in terms of P only suggests whether there is any difference in probability terms. Use of the CI supplements the P value by providing an estimate of actual clinical effect. Of late, clinical trials are being designed specifically as superiority, non-inferiority or equivalence studies. The conclusions from these alternative trial designs are based on CI values rather than the P value from intergroup comparison.},
	an = {29268424},
	author = {Hazra, Avijit},
	date = {2017/10/},
	date-added = {2020-11-10 12:00:55 -0600},
	date-modified = {2020-11-10 12:01:07 -0600},
	db = {PubMed},
	doi = {10.21037/jtd.2017.09.14},
	isbn = {2072-1439; 2077-6624},
	j2 = {J Thorac Dis},
	journal = {Journal of thoracic disease},
	keywords = {Confidence interval (CI); P value; clinical significance; confidence level; statistical inference},
	l2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5723800/},
	la = {eng},
	month = {10},
	number = {10},
	pages = {4125--4130},
	publisher = {AME Publishing Company},
	title = {Using the confidence interval confidently},
	ty = {JOUR},
	u1 = {29268424{$[$}pmid{$]$}},
	u2 = {PMC5723800{$[$}pmcid{$]$}},
	u4 = {jtd-09-10-4125{$[$}PII{$]$}},
	url = {https://pubmed.ncbi.nlm.nih.gov/29268424},
	volume = {9},
	year = {2017},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/29268424},
	Bdsk-Url-2 = {https://doi.org/10.21037/jtd.2017.09.14}}

@article{residual,
	author = {Martin Law and Dan Jackson},
	date-added = {2020-11-10 11:58:45 -0600},
	date-modified = {2020-11-10 11:58:58 -0600},
	doi = {10.1080/03610918.2015.1076470},
	eprint = {https://doi.org/10.1080/03610918.2015.1076470},
	journal = {Communications in Statistics - Simulation and Computation},
	number = {4},
	pages = {3159-3171},
	publisher = {Taylor & Francis},
	title = {Residual plots for linear regression models with censored outcome data: A refined method for visualizing residual uncertainty},
	url = {https://doi.org/10.1080/03610918.2015.1076470},
	volume = {46},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1080/03610918.2015.1076470}}

@article{assumptions,
	abstract = {Abstract Linear regression (LR) is a powerful statistical model when used correctly. Because the model is an approximation of the long-term sequence of any event, it requires assumptions to be made about the data it represents in order to remain appropriate. However, these assumptions are often misunderstood. We present the basic assumptions used in the LR model and offer a simple methodology for checking if they are satisfied prior to its use. In doing so, we aim to increase the effectiveness and appropriateness of LR in clinical research.},
	author = {Casson, Robert J and Farmer, Lachlan DM},
	date-added = {2020-11-10 11:56:54 -0600},
	date-modified = {2020-11-10 11:57:13 -0600},
	doi = {https://doi.org/10.1111/ceo.12358},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ceo.12358},
	journal = {Clinical \& Experimental Ophthalmology},
	keywords = {assumption, normality, regression, statistics},
	number = {6},
	pages = {590-596},
	title = {Understanding and checking the assumptions of linear regression: a primer for medical researchers},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ceo.12358},
	volume = {42},
	year = {2014},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ceo.12358},
	Bdsk-Url-2 = {https://doi.org/10.1111/ceo.12358}}

@book{wick,
	abstract = {Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible. Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. Youll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what youve learned along the way. Youll learn how to: Wrangletransform your datasets into a form convenient for analysisProgramlearn powerful R tools for solving data problems with greater clarity and easeExploreexamine your data, generate hypotheses, and quickly test themModelprovide a low-dimensional summary that captures true "signals" in your datasetCommunicatelearn R Markdown for integrating prose, code, and results},
	author = {Wickham, Hadley and Grolemund, Garrett},
	date-added = {2020-11-10 11:53:51 -0600},
	date-modified = {2020-11-10 11:54:53 -0600},
	edition = {1st},
	isbn = {1491910399},
	publisher = {O'Reilly Media, Inc.},
	title = {R for Data Science: Import, Tidy, Transform, Visualize, and Model Data},
	year = {2017}}

@electronic{r2,
	abstract = {Abstract R-squared and adjusted R-squared are statistics derived from analyses based on the general linear model (e.g., regression, ANOVA). It represents the proportion of variance in the outcome variable which is explained by the predictor variables in the sample (R-squared) and an estimate in the population (adjusted R-squared).},
	author = {Miles, Jeremy},
	booktitle = {Wiley StatsRef: Statistics Reference Online},
	date-added = {2020-11-10 11:49:38 -0600},
	date-modified = {2020-11-10 11:52:32 -0600},
	doi = {https://doi.org/10.1002/9781118445112.stat06627},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118445112.stat06627},
	isbn = {9781118445112},
	keywords = {ANOVA, least squares, proportion of variance, regression},
	publisher = {American Cancer Society},
	title = {R Squared, Adjusted R Squared},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat06627},
	year = {2014},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat06627},
	Bdsk-Url-2 = {https://doi.org/10.1002/9781118445112.stat06627}}

@article{aic,
	author = {Hamparsum Bozdogan},
	date-added = {2020-11-10 11:47:36 -0600},
	date-modified = {2020-11-10 11:48:01 -0600},
	doi = {10.1007/bf02294361},
	journal = {Psychometrika},
	month = {sep},
	number = {3},
	pages = {345--370},
	publisher = {Springer Science and Business Media {LLC}},
	title = {Model selection and Akaike's Information Criterion AIC: The general theory and its analytical extensions},
	url = {https://doi.org/10.1007%2Fbf02294361},
	volume = {52},
	year = 1987,
	Bdsk-Url-1 = {https://doi.org/10.1007%2Fbf02294361},
	Bdsk-Url-2 = {https://doi.org/10.1007/bf02294361}}

@book{book,
	address = {Belmont},
	author = {William M. Mendenhall and Terry L. Sincich},
	date-added = {2020-11-10 11:45:13 -0600},
	date-modified = {2020-11-10 11:45:13 -0600},
	edition = {6},
	publisher = {Duxbury Press},
	title = {Probability and statistics for engineering and the sciences.},
	type = {Book},
	volume = {6},
	year = {1995}}

@misc{jim,
	author = {Jim Frost},
	date-added = {2020-11-10 11:37:58 -0600},
	date-modified = {2020-11-10 11:42:00 -0600},
	howpublished = {Webpage},
	keywords = {Statistics By Jim},
	title = {Multicollinearity in Regression Analysis: Problems, Detection, and Solutions},
	urldate = {https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/},
	year = {2020}}
